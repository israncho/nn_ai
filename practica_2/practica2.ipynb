{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification(r0=1,r1=3,k=1000):\n",
    "    \"\"\"\n",
    "    Creaci ́on de los datos\n",
    "    \"\"\"\n",
    "    X1 = [np.array([r0*np.cos(t),r0*np.sin(t)]) for t in range(0,k)]\n",
    "    X2 = [np.array([r1*np.cos(t),r1*np.sin(t)]) for t in range(0,k)]\n",
    "    X = np.concatenate((X1,X2))\n",
    "    n,d = X.shape\n",
    "    Y = np.zeros((2*k,2))\n",
    "    Y[0:k] += [1,0]\n",
    "    Y[k:] += [0,1]\n",
    "    noise = np.array([np.random.normal(0,1,2) for i in range(n)])\n",
    "    X += 0.5*noise\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(k=10)\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(X, Y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \"\"\"Nodo super clase con funciones generales\"\"\"\n",
    "    def __init__(self, value):\n",
    "    # Agrega los par ́ametros necesarios\n",
    "        self.value = value\n",
    "        self.grad = None\n",
    "        return\n",
    "        \n",
    "    def __call__(self, *kwargs):\n",
    "        return self.forward(*kwargs)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.value) #Valor n ́um del nodo\n",
    "        \n",
    "    def backward(self, consumer_grad=1):\n",
    "        self.grad = consumer_grad\n",
    "# Agrega otros m ́etodos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Clases basicas\n",
    "\n",
    "class PreActivation(Node):\n",
    "    # Pre-activación wx+b\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # Generamos una matriz aleatoria de tamaño input x output \n",
    "        # Y la trasponemos para usarla como matriz\n",
    "        self.w = np.random.uniform(0,1,(input_size, output_size)).T\n",
    "        \n",
    "        # Generamos el vector de sesgo del tamaño de salida\n",
    "        self.b = np.random.uniform(0,1, output_size).T # Bias\n",
    "        print(self.w)\n",
    "        print(self.b)\n",
    "        # Guardamos estos parámetros\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        return None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Función que activa el nodo\n",
    "        self.parent = x\n",
    "        self.value = np.dot(self.w, x.value) + self.b # Expresión lineal\n",
    "        return self\n",
    "\n",
    "    def backward(self, consumer_grad=1):\n",
    "        # La función backward recibe el gradiente de los nodos hijos y regresa el gradiente\n",
    "        self.grad = self.parent.value\n",
    "        self.parent.backward(self.grad)\n",
    "        return self  \n",
    "\n",
    "    def update(self, consumer_grad):\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Node):\n",
    "    # Activación ReLU\n",
    "\n",
    "    def __init__(self,node):\n",
    "        self.preactivation = node\n",
    "        return None\n",
    "\n",
    "    def function(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.parent = x\n",
    "        self.value = self.function(self.preactivation(self.parent).value)\n",
    "        return self\n",
    "\n",
    "    def backward(self, consumer_grad):\n",
    "        m = self.preactivation.output_size\n",
    "        \n",
    "        dh_da = np.zeros(m)\n",
    "        for i in range(m):\n",
    "            dh_da[i] = 1 - self.value[i]**2\n",
    "\n",
    "        d_k = dh_da * consumer_grad\n",
    "        self.grad = d_k\n",
    "        print(f\"Tanh d_k = {d_k}\")\n",
    "        # Calculamos la suma d_k+1 * W_q,i para pasarla al siguiente nodo\n",
    "        n = self.preactivation.input_size\n",
    "        d_kW = np.zeros(m)\n",
    "        for i in range(n):\n",
    "            for q in range(m):\n",
    "                d_kW[q] += d_k[q] * self.preactivation.w[q][i]\n",
    "\n",
    "        self.parent.backward(d_kW)\n",
    "\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Node):\n",
    "    # Activación ReLU\n",
    "\n",
    "    def __init__(self,node):\n",
    "        self.preactivation = node\n",
    "        return None\n",
    "\n",
    "    def function(self, x):\n",
    "        return x * (x > 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.parent = x\n",
    "        self.value = self.function(self.preactivation(self.parent).value)\n",
    "        return self\n",
    "\n",
    "    def backward(self, consumer_grad):\n",
    "        m = self.preactivation.output_size\n",
    "\n",
    "        dh_da = np.zeros(m)\n",
    "        for i in range(m):\n",
    "            # Calculamos la derivada de ReLu respecto a su preactivación a\n",
    "            if self.preactivation.value[i] >= 0:\n",
    "                dh_da[i] = 1\n",
    "            else:\n",
    "                dh_da[i] = 0\n",
    "        \n",
    "        d_k = dh_da * consumer_grad\n",
    "        self.grad = d_k\n",
    "        print(f\"ReLu d_k = {d_k}\")\n",
    "        # Calculamos la suma d_k+1 * W_q,i para pasarla al siguiente nodo\n",
    "\n",
    "        n = self.preactivation.input_size\n",
    "        d_kW = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            for q in range(m):\n",
    "                d_kW[q] += d_k[q] * self.preactivation.w[q][i]\n",
    "            \n",
    "        self.parent.backward(d_kW)\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Node):\n",
    "    # Activación ReLU\n",
    "\n",
    "    def __init__(self,node):\n",
    "        self.preactivation = node\n",
    "        return None\n",
    "\n",
    "    def function(self, x):\n",
    "        S = sum( [np.exp(x_i) for x_i in x] )\n",
    "        return np.exp(x) / S\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.parent = x\n",
    "        self.value = self.function(self.preactivation(self.parent).value)\n",
    "        return self\n",
    "\n",
    "    def backward(self, consumer_grad):\n",
    "        m = self.preactivation.output_size\n",
    "\n",
    "        df_da = np.zeros(m)\n",
    "        for i in range(m):\n",
    "            x = self.value[i]\n",
    "            df_da[i] =  x*(1-x)\n",
    "\n",
    "        d_k = consumer_grad * df_da\n",
    "        print(f\"softmax d_k = {d_k}\")\n",
    "        self.grad = d_k\n",
    "\n",
    "        # Calculamos la suma d_k+1 * W_q,i para pasarla al siguiente nodo\n",
    "        n = self.preactivation.input_size\n",
    "        d_kW = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            for q in range(m):\n",
    "                d_kW[q] += d_k[q] * self.preactivation.w[q][i]\n",
    "\n",
    "        self.parent.backward(d_kW)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy(Node):\n",
    "    # Error de clasificación binario\n",
    "    def __init__(self, output_node):\n",
    "        self.parent = output_node\n",
    "        return None\n",
    "\n",
    "    def forward(self, Y_real):\n",
    "        # Definido por casos para evitar infinitos innecesarios\n",
    "        epsilon = sys.float_info.epsilon\n",
    "        self.real_output = Y_real\n",
    "    \n",
    "        add = 0\n",
    "        for y_pred, y_real in zip(self.parent.value, Y_real):\n",
    "            add -= y_real * np.log(y_pred + epsilon)\n",
    "        \n",
    "        self.value = add\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def backward(self, consumer_grad = 1):\n",
    "        dL_df = - self.real_output / self.parent.value\n",
    "        self.grad = dL_df * consumer_grad\n",
    "        print(f\"dL_df = {self.grad}\")\n",
    "        self.parent.backward(self.grad)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45534135 0.27524145]\n",
      " [0.09271912 0.16742675]\n",
      " [0.16438683 0.36372621]]\n",
      "[0.0639517  0.96479423 0.46107253]\n",
      "[[0.42921124 0.58489117 0.50757214]\n",
      " [0.20038538 0.63435382 0.80153569]]\n",
      "[0.60209484 0.0099548 ]\n",
      "[[0.25553991 0.79513999]\n",
      " [0.1873873  0.62575499]]\n",
      "[0.37176567 0.69626575]\n"
     ]
    }
   ],
   "source": [
    "# Arquitectura de la Red\n",
    "tanh_layer = Tanh( PreActivation(2, 3) )\n",
    "relu_layer = ReLU( PreActivation(3,2) )\n",
    "softmax_layer = Softmax( PreActivation(2,2) )\n",
    "\n",
    "error = CrossEntropy(softmax_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.68599333, -1.56861369]), array([1., 0.]))"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88630298 0.84670913 0.74464401]\n",
      "[1.85569929 1.32152888]\n",
      "[0.5064541 0.4935459]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6803215817064229)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_node = Node(x_train[1])\n",
    "\n",
    "l_0 = tanh_layer(initial_node)\n",
    "print(l_0)\n",
    "\n",
    "l_1 = relu_layer(l_0)\n",
    "print(l_1)\n",
    "\n",
    "l_2 = softmax_layer(l_1)\n",
    "print(l_2)\n",
    "\n",
    "\n",
    "error(y_train[0]).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_df = [-1.9745126 -0.       ]\n",
      "softmax d_k = [-0.4935459 -0.       ]\n",
      "ReLu d_k = [-0.51855876  0.        ]\n",
      "Tanh d_k = [-0.16923114  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
